{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\t\t  model.py\t\tscaling_laws.ipynb\n",
      "bench.py\t  out\t\t\tsrc\n",
      "BranchyGPT.ipynb  out-shakespeare-char\ttrain.py\n",
      "config\t\t  __pycache__\t\ttransformer_sizing.ipynb\n",
      "configurator.py   README.md\t\twandb\n",
      "data\t\t  rejectOption.py\n",
      "LICENSE\t\t  sample.py\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branchy GPT\n",
    "\n",
    "In this notebook we will try to train a custom BranchyGPT for experiment on Shakespeare_char dataset for experimental purposes, It might scale further to openwebtext after.\n",
    "\n",
    "First please run \n",
    "\n",
    "    python data/shakespeare_char/prepare.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f01701129b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "\n",
    "from model import GPTConfig, GPT\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up checkpoint saving directory\n",
    "out_dir = \"./BranchyGPT_save\"\n",
    "dataset = \"shakespeare_char\"\n",
    "dtype = torch.float16\n",
    "\n",
    "# Get device between GPU or CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ctx = nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=dtype)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "\n",
    "#Prepare dataset\n",
    "gradient_accumulation_steps = 1 # used to simulate larger batch sizes\n",
    "batch_size = 128\n",
    "data_dir = os.path.join('data', dataset)\n",
    "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint16, mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 29.96M\n",
      "GPTConfig(block_size=256, vocab_size=50304, n_layer=6, n_head=6, n_embd=384, dropout=0.0, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Get default conf, model is GPT2\n",
    "gptconf = GPTConfig()\n",
    "gptconf.block_size = 256\n",
    "gptconf.n_layer = 6\n",
    "gptconf.n_head = 6\n",
    "gptconf.n_embd = 384\n",
    "model = GPT(gptconf)\n",
    "model.to(device)\n",
    "print(gptconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 26, with 30,031,872 parameters\n",
      "num non-decayed parameter tensors: 50, with 30,720 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n"
     ]
    }
   ],
   "source": [
    "# adamw optimizer\n",
    "learning_rate = 1e-3 # max learning rate\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n",
    "\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device)\n",
    "\n",
    "if compile:\n",
    "    print(\"compiling the model... (takes a ~minute)\")\n",
    "    unoptimized_model = model\n",
    "    model = torch.compile(model) # requires PyTorch 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, block_size, batch_size, device):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    if device == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "X, Y = get_batch('train', gptconf.block_size, batch_size, device) # fetch the very first batch\n",
    "\n",
    "eval_iters = 200 # how many iterations to average loss over when evaluating\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, gptconf.block_size, batch_size, device)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-20 11:51:04,358] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg77_1, i1 + 256 * i0)\n",
      "    tmp1 = load(arg26_1, i2 + 384 * (tmp0))\n",
      "    tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "    tmp3 = load(arg27_1, i2 + 384 * (tmp2))\n",
      "    tmp4 = tmp1 + tmp3\n",
      "    tmp5 = load(buf1, i1 + 256 * i0)\n",
      "    tmp6 = tmp4 - tmp5\n",
      "    tmp7 = load(buf2, i1 + 256 * i0)\n",
      "    tmp8 = index_expr(384, torch.float32)\n",
      "    tmp9 = tmp7 / tmp8\n",
      "    tmp10 = constant(1e-05, torch.float32)\n",
      "    tmp11 = tmp9 + tmp10\n",
      "    tmp12 = rsqrt(tmp11)\n",
      "    tmp13 = tmp6 * tmp12\n",
      "    return tmp13\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={mul, embedding, arg26_1, add, iota, add_1, sub, arg77_1, unsqueeze, var_mean, arg27_1, embedding_1, rsqrt}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,363] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg77_1, i1 + 256 * i0)\n",
      "    tmp1 = load(arg26_1, i2 + 384 * (tmp0))\n",
      "    tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "    tmp3 = load(arg27_1, i2 + 384 * (tmp2))\n",
      "    tmp4 = tmp1 + tmp3\n",
      "    tmp5 = load(buf1, i1 + 256 * i0)\n",
      "    tmp6 = tmp4 - tmp5\n",
      "    tmp7 = load(buf2, i1 + 256 * i0)\n",
      "    tmp8 = index_expr(384, torch.float32)\n",
      "    tmp9 = tmp7 / tmp8\n",
      "    tmp10 = constant(1e-05, torch.float32)\n",
      "    tmp11 = tmp9 + tmp10\n",
      "    tmp12 = rsqrt(tmp11)\n",
      "    tmp13 = tmp6 * tmp12\n",
      "    tmp14 = load(arg0_1, i2)\n",
      "    tmp15 = tmp13 * tmp14\n",
      "    return tmp15\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={mul, embedding, arg26_1, add, mul_1, iota, add_1, sub, arg77_1, unsqueeze, arg0_1, var_mean, arg27_1, embedding_1, rsqrt}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,425] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg77_1, i1 + 256 * i0)\n",
      "    tmp1 = load(arg26_1, i2 + 384 * (tmp0))\n",
      "    tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "    tmp3 = load(arg27_1, i2 + 384 * (tmp2))\n",
      "    tmp4 = tmp1 + tmp3\n",
      "    tmp5 = load(buf12, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp6 = to_dtype(tmp5, torch.float32)\n",
      "    tmp7 = tmp4 + tmp6\n",
      "    tmp8 = load(buf14, i1 + 256 * i0)\n",
      "    tmp9 = tmp7 - tmp8\n",
      "    tmp10 = load(buf15, i1 + 256 * i0)\n",
      "    tmp11 = index_expr(384, torch.float32)\n",
      "    tmp12 = tmp10 / tmp11\n",
      "    tmp13 = constant(1e-05, torch.float32)\n",
      "    tmp14 = tmp12 + tmp13\n",
      "    tmp15 = rsqrt(tmp14)\n",
      "    tmp16 = tmp9 * tmp15\n",
      "    return tmp16\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, convert_element_type_4, convert_element_type_2, iota, add_1, mul_2, arg0_1, unsqueeze, permute, permute_1, view_3, view_1, arg1_1, add_3, mul, mul_1, arg77_1, sub, view_2, rsqrt_1, view_7, var_mean, permute_5, convert_element_type_3, add_2, rsqrt, convert_element_type, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, add_4, add, permute_4, arg30_1, view_6, addmm, split, addmm_1, view_5, var_mean_1, arg29_1, view, permute_3, arg28_1, sub_1, arg27_1, embedding_1, permute_2, convert_element_type_1}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,430] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg77_1, i1 + 256 * i0)\n",
      "    tmp1 = load(arg26_1, i2 + 384 * (tmp0))\n",
      "    tmp2 = index_expr(i1, dtype=torch.int64)\n",
      "    tmp3 = load(arg27_1, i2 + 384 * (tmp2))\n",
      "    tmp4 = tmp1 + tmp3\n",
      "    tmp5 = load(buf12, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp6 = to_dtype(tmp5, torch.float32)\n",
      "    tmp7 = tmp4 + tmp6\n",
      "    tmp8 = load(buf14, i1 + 256 * i0)\n",
      "    tmp9 = tmp7 - tmp8\n",
      "    tmp10 = load(buf15, i1 + 256 * i0)\n",
      "    tmp11 = index_expr(384, torch.float32)\n",
      "    tmp12 = tmp10 / tmp11\n",
      "    tmp13 = constant(1e-05, torch.float32)\n",
      "    tmp14 = tmp12 + tmp13\n",
      "    tmp15 = rsqrt(tmp14)\n",
      "    tmp16 = tmp9 * tmp15\n",
      "    tmp17 = load(arg2_1, i2)\n",
      "    tmp18 = tmp16 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, convert_element_type_4, convert_element_type_2, iota, add_1, mul_2, arg0_1, unsqueeze, permute, permute_1, view_3, view_1, arg1_1, add_3, mul, arg2_1, mul_3, mul_1, arg77_1, sub, view_2, rsqrt_1, view_7, var_mean, permute_5, convert_element_type_3, add_2, rsqrt, convert_element_type, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, add_4, add, permute_4, arg30_1, view_6, addmm, split, addmm_1, view_5, var_mean_1, arg29_1, view, permute_3, arg28_1, sub_1, arg27_1, embedding_1, permute_2, convert_element_type_1}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,441] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg26_1, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, mul, arg2_1, mul_1, arg77_1, view_2, rsqrt_1, arg3_1, view_7, mul_4, add_2, rsqrt, convert_element_type, add_4, add, addmm_1, var_mean_1, addmm_2, sub_1, embedding_1, view_8, convert_element_type_5, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, view_1, add_3, mul_3, arg33_1, sub, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, arg30_1, view_6, addmm, split, view_5, arg29_1, view, convert_element_type_6, permute_3, arg28_1, view_9, arg27_1, permute_2, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,446] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg26_1, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, mul, arg2_1, mul_1, arg77_1, view_2, rsqrt_1, arg3_1, view_7, add_2, rsqrt, convert_element_type, add_4, add, addmm_1, var_mean_1, addmm_2, sub_1, embedding_1, view_8, convert_element_type_5, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, view_1, add_3, mul_3, arg33_1, sub, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, arg30_1, view_6, addmm, split, view_5, arg29_1, view, convert_element_type_6, convert_element_type_8, permute_3, pow_1, arg28_1, mul_5, view_9, arg27_1, permute_2, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,450] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg26_1, mul_6, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, mul, arg2_1, mul_1, arg77_1, view_2, rsqrt_1, arg3_1, view_7, add_2, rsqrt, convert_element_type, add_4, add, addmm_1, var_mean_1, addmm_2, sub_1, add_6, embedding_1, view_8, convert_element_type_5, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, view_1, add_3, mul_3, arg33_1, sub, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, arg30_1, view_6, addmm, split, view_5, arg29_1, view, convert_element_type_6, convert_element_type_8, permute_3, arg28_1, pow_1, mul_5, view_9, arg27_1, permute_2, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,456] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf19, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg26_1, mul_6, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, mul, arg2_1, mul_1, arg77_1, view_2, rsqrt_1, arg3_1, view_7, mul_4, add_2, rsqrt, convert_element_type, tanh, add_4, add, addmm_1, var_mean_1, addmm_2, sub_1, add_6, embedding_1, view_8, convert_element_type_5, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, view_1, add_3, mul_3, arg33_1, sub, mul_7, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, add_7, arg30_1, view_6, addmm, split, view_5, arg29_1, view, convert_element_type_6, convert_element_type_8, permute_3, arg28_1, pow_1, mul_5, view_9, arg27_1, permute_2, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,483] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf26, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf27, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, mul_6, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, permute_7, convert_element_type_10, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, rsqrt_1, view_7, mul_4, add_2, rsqrt, convert_element_type, tanh, add_4, add, rsqrt_2, addmm_1, var_mean_1, view_11, add_8, addmm_2, sub_1, add_6, embedding_1, view_8, convert_element_type_5, var_mean_2, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, arg35_1, view_1, add_3, arg34_1, mul_3, arg33_1, mul_8, sub, mul_7, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, add_7, arg30_1, view_6, addmm, view_10, split, view_5, arg29_1, convert_element_type_11, view, convert_element_type_6, convert_element_type_8, convert_element_type_9, permute_3, arg28_1, pow_1, mul_5, view_9, arg27_1, permute_2, addmm_3, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,486] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf26, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf27, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    tmp10 = load(arg4_1, i2)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    return tmp11\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, mul_6, convert_element_type_4, iota, arg0_1, unsqueeze, permute_1, view_3, arg1_1, permute_7, convert_element_type_10, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, rsqrt_1, view_7, mul_4, add_2, arg4_1, rsqrt, convert_element_type, tanh, add_4, add, rsqrt_2, addmm_1, var_mean_1, view_11, add_8, addmm_2, sub_1, add_6, embedding_1, view_8, convert_element_type_5, var_mean_2, convert_element_type_1, permute_6, convert_element_type_2, permute, add_1, mul_2, arg35_1, view_1, add_3, arg34_1, mul_9, mul_3, arg33_1, mul_8, sub, mul_7, var_mean, permute_5, arg32_1, convert_element_type_3, add_5, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_4, add_7, arg30_1, view_6, addmm, view_10, split, view_5, arg29_1, convert_element_type_11, view, convert_element_type_6, convert_element_type_8, convert_element_type_9, permute_3, arg28_1, pow_1, mul_5, view_9, arg27_1, permute_2, addmm_3, convert_element_type_7}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,517] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf39, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf40, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, mul_6, convert_element_type_4, addmm_5, iota, arg0_1, unsqueeze, permute_1, view_3, view_16, arg1_1, convert_element_type_13, permute_7, rsqrt_3, convert_element_type_10, mul, arg2_1, add_9, mul_1, add_12, addmm_4, arg77_1, view_2, arg3_1, rsqrt_1, view_7, mul_4, add_2, arg4_1, rsqrt, convert_element_type_16, convert_element_type, tanh, view_17, add_4, arg5_1, add, rsqrt_2, addmm_1, var_mean_1, var_mean_3, mul_10, arg39_1, view_11, convert_element_type_14, permute_12, add_8, addmm_2, arg38_1, sub_1, add_6, embedding_1, view_8, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, convert_element_type_12, split_1, arg36_1, permute_6, convert_element_type_2, permute, add_1, mul_2, arg35_1, view_12, view_13, view_1, view_14, add_3, arg34_1, mul_9, mul_3, arg33_1, mul_8, sub, mul_7, var_mean, permute_11, permute_5, arg32_1, convert_element_type_3, add_5, sub_2, view_4, sub_3, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_9, permute_8, permute_4, permute_13, add_7, arg30_1, view_6, view_15, addmm, view_10, split, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, convert_element_type_8, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, mul_5, view_9, arg27_1, permute_2, addmm_3, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,521] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf39, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf40, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    tmp13 = load(arg6_1, i2)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    return tmp14\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg26_1, addmm_5, convert_element_type_4, mul_6, iota, arg0_1, unsqueeze, permute_1, view_3, view_16, arg1_1, convert_element_type_13, permute_7, rsqrt_3, convert_element_type_10, mul, arg2_1, add_9, mul_1, add_12, addmm_4, arg77_1, view_2, arg3_1, rsqrt_1, view_7, mul_4, add_2, arg4_1, rsqrt, convert_element_type_16, convert_element_type, tanh, view_17, add_4, arg5_1, add, rsqrt_2, addmm_1, var_mean_1, var_mean_3, mul_10, arg39_1, view_11, convert_element_type_14, permute_12, add_8, addmm_2, arg38_1, sub_1, add_6, embedding_1, view_8, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, convert_element_type_12, split_1, arg36_1, permute_6, convert_element_type_2, permute, add_1, mul_2, arg35_1, view_12, view_13, view_1, view_14, add_3, arg34_1, mul_9, mul_3, arg33_1, mul_8, sub, mul_7, var_mean, permute_11, permute_5, arg32_1, mul_11, convert_element_type_3, add_5, sub_2, view_4, sub_3, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_9, permute_8, permute_4, permute_13, add_7, arg30_1, view_6, arg6_1, view_15, addmm, view_10, split, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, convert_element_type_8, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, mul_5, view_9, arg27_1, permute_2, addmm_3, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,530] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, mul_10, arg39_1, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, view_14, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, permute_13, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, arg26_1, mul_6, addmm_5, iota, unsqueeze, permute_1, view_3, convert_element_type_13, permute_7, rsqrt_3, convert_element_type_10, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_3, permute_9, convert_element_type_17, permute_4, add_7, view_6, arg6_1, addmm, view_10, split, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_5, view_9, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,535] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, mul_10, arg39_1, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, view_14, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, permute_13, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, arg26_1, mul_6, addmm_5, iota, unsqueeze, permute_1, view_3, convert_element_type_13, permute_7, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_3, permute_9, convert_element_type_17, permute_4, add_7, view_6, arg6_1, addmm, view_10, split, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, mul_5, view_9, pow_2, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,539] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, add_2, arg4_1, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, mul_10, arg39_1, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, view_14, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, permute_13, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, add_14, arg26_1, mul_6, addmm_5, iota, unsqueeze, permute_1, view_3, convert_element_type_13, permute_7, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_3, permute_9, convert_element_type_17, permute_4, add_7, view_6, arg6_1, addmm, view_10, split, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, mul_5, view_9, pow_2, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,545] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf44, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, add_2, arg4_1, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, mul_10, arg39_1, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, view_14, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, permute_13, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, arg26_1, add_14, mul_6, addmm_5, iota, unsqueeze, permute_1, view_3, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, mul_15, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_3, permute_9, convert_element_type_17, permute_4, add_7, view_6, arg6_1, addmm, view_10, split, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, mul_5, view_9, pow_2, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,561] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf48, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf50, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf51, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    return tmp15\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, add_2, arg4_1, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, permute_13, view_22, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, arg26_1, add_14, addmm_5, mul_6, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, addmm_7, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, mul_15, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, convert_element_type_21, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, mul_5, add_16, view_9, convert_element_type_22, pow_2, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,565] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf48, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf50, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf51, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    tmp16 = load(arg8_1, i2)\n",
      "    tmp17 = tmp15 * tmp16\n",
      "    return tmp17\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={convert_element_type_4, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, add_9, mul_1, arg77_1, view_2, arg3_1, view_7, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, convert_element_type_2, permute, arg35_1, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, mul_9, convert_element_type_18, arg33_1, mul_8, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, permute_13, view_22, arg30_1, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, view_19, arg27_1, permute_2, addmm_3, convert_element_type_19, arg26_1, add_14, addmm_5, mul_17, mul_6, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, addmm_4, rsqrt_1, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, add, addmm_7, add_13, view_20, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, sub_1, add_6, embedding_1, view_8, mul_15, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, mul_7, var_mean, permute_11, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, convert_element_type_21, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, pow_2, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,598] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf48, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf61, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp8 = to_dtype(tmp7, torch.float32)\n",
      "    tmp9 = tmp6 + tmp8\n",
      "    tmp10 = load(buf63, i1 + 256 * i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = load(buf64, i1 + 256 * i0)\n",
      "    tmp13 = index_expr(384, torch.float32)\n",
      "    tmp14 = tmp12 / tmp13\n",
      "    tmp15 = constant(1e-05, torch.float32)\n",
      "    tmp16 = tmp14 + tmp15\n",
      "    tmp17 = rsqrt(tmp16)\n",
      "    tmp18 = tmp11 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_4, convert_element_type_25, arg0_1, view_31, view_16, arg1_1, mul, permute_15, arg2_1, add_9, mul_1, permute_16, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, view_26, tanh, permute_19, add, addmm_7, split_2, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, embedding_1, view_8, mul_15, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,602] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf24, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf37, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf48, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf61, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp8 = to_dtype(tmp7, torch.float32)\n",
      "    tmp9 = tmp6 + tmp8\n",
      "    tmp10 = load(buf63, i1 + 256 * i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = load(buf64, i1 + 256 * i0)\n",
      "    tmp13 = index_expr(384, torch.float32)\n",
      "    tmp14 = tmp12 / tmp13\n",
      "    tmp15 = constant(1e-05, torch.float32)\n",
      "    tmp16 = tmp14 + tmp15\n",
      "    tmp17 = rsqrt(tmp16)\n",
      "    tmp18 = tmp11 * tmp17\n",
      "    tmp19 = load(arg10_1, i2)\n",
      "    tmp20 = tmp18 * tmp19\n",
      "    return tmp20\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_4, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, add_9, mul_1, permute_16, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, mul_19, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, view_26, tanh, permute_19, add, addmm_7, split_2, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, embedding_1, view_8, mul_15, addmm_6, convert_element_type_12, permute_6, add_1, mul_2, view_12, view_13, permute_14, mul_14, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,613] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, mul_19, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, addmm_10, view_26, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, mul_15, addmm_6, view_32, convert_element_type_12, permute_6, arg49_1, add_1, mul_2, arg48_1, view_12, view_13, permute_14, convert_element_type_30, mul_14, mul_20, permute_22, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,618] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, pow_3, arg2_1, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, mul_19, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, mul_21, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, addmm_10, view_26, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, convert_element_type_32, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, mul_15, addmm_6, view_32, convert_element_type_12, permute_6, arg49_1, add_1, mul_2, arg48_1, view_12, view_13, permute_14, convert_element_type_30, mul_14, permute_22, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,622] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, mul_22, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, mul_19, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, mul_21, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, addmm_10, view_26, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, convert_element_type_32, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, mul_15, addmm_6, view_32, convert_element_type_12, permute_6, arg49_1, add_1, mul_2, arg48_1, view_12, view_13, permute_14, convert_element_type_30, mul_14, add_22, permute_22, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,628] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf68, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, view_17, add_4, arg5_1, arg41_1, permute_17, rsqrt_2, mul_23, arg40_1, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, mul_22, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, sub_5, arg31_1, _scaled_dot_product_efficient_attention, permute_8, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, mul_19, convert_element_type_19, convert_element_type_28, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, mul_21, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, add_12, mul_18, addmm_4, rsqrt_1, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, addmm_10, view_26, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, convert_element_type_32, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, add_23, mul_15, addmm_6, view_32, convert_element_type_12, permute_6, arg49_1, add_1, mul_2, arg48_1, view_12, view_13, permute_14, convert_element_type_30, mul_14, add_22, mul_20, permute_22, mul_3, sub, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,644] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf75, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf76, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, addmm_11, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, permute_23, arg4_1, add_2, convert_element_type_33, view_17, add_4, arg5_1, arg41_1, add_11, permute_17, rsqrt_2, arg40_1, mul_23, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, mul_22, arg38_1, convert_element_type_5, var_mean_2, arg37_1, convert_element_type_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, convert_element_type_19, convert_element_type_28, mul_19, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, mul_21, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, mul_24, add_12, mul_18, addmm_4, rsqrt_1, permute_20, view_34, mul_4, rsqrt, convert_element_type_16, convert_element_type, view_26, addmm_10, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, convert_element_type_32, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, arg51_1, add_23, mul_15, addmm_6, view_32, arg50_1, convert_element_type_12, permute_6, add_1, add_24, mul_2, arg49_1, arg48_1, convert_element_type_35, view_12, view_13, permute_14, convert_element_type_30, view_35, mul_14, add_22, mul_20, permute_22, mul_3, sub, sub_6, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,648] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf75, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf76, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    tmp10 = load(arg12_1, i2)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    return tmp11\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_31, convert_element_type_4, addmm_11, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, add_9, mul_1, permute_16, view_33, arg77_1, view_2, arg3_1, view_7, pow_2, mul_25, permute_23, arg4_1, add_2, convert_element_type_33, view_17, add_4, arg5_1, arg41_1, add_11, permute_17, rsqrt_2, arg40_1, mul_23, addmm_1, arg39_1, mul_10, convert_element_type_14, add_8, mul_22, arg38_1, convert_element_type_5, var_mean_2, convert_element_type_1, arg37_1, split_1, arg36_1, add_20, convert_element_type_2, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, mul_9, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_8, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, sub_2, view_4, embedding, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, permute_13, view_22, arg30_1, permute_21, view_15, add_10, view_5, convert_element_type_15, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, convert_element_type_9, permute_3, view_18, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, addmm_3, convert_element_type_19, convert_element_type_28, mul_19, _scaled_dot_product_efficient_attention_2, arg26_1, add_14, mul_21, addmm_5, mul_6, mul_17, view_27, iota, unsqueeze, permute_1, view_3, add_17, convert_element_type_13, permute_7, add_15, rsqrt_3, convert_element_type_10, convert_element_type_20, mul_24, add_12, mul_18, addmm_4, rsqrt_1, permute_20, view_34, mul_4, rsqrt, convert_element_type_16, convert_element_type, view_26, addmm_10, tanh, permute_19, add, addmm_7, split_2, convert_element_type_29, convert_element_type_32, add_13, view_20, var_mean_5, var_mean_1, var_mean_3, view_11, permute_12, addmm_2, view_28, sub_1, add_6, add_21, embedding_1, view_8, arg51_1, add_23, mul_15, addmm_6, view_32, arg50_1, convert_element_type_12, permute_6, add_1, add_24, mul_2, arg49_1, arg48_1, convert_element_type_35, view_12, view_13, permute_14, convert_element_type_30, view_35, mul_14, add_22, mul_20, permute_22, mul_3, arg12_1, sub, sub_6, arg45_1, mul_7, var_mean, permute_11, arg46_1, arg11_1, mul_11, convert_element_type_3, add_5, sub_4, sub_3, permute_9, permute_18, convert_element_type_21, arg44_1, arg10_1, convert_element_type_17, view_23, permute_4, arg43_1, add_7, view_6, arg6_1, addmm, view_10, split, arg42_1, _scaled_dot_product_efficient_attention_1, view, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, arg8_1, mul_5, add_16, view_9, convert_element_type_22, convert_element_type_26, arg9_1, convert_element_type_23, convert_element_type_7, permute_10, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,678] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf88, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf89, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_4, addmm_11, add_9, arg77_1, mul_25, permute_23, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, sub_2, embedding, permute_13, add_10, convert_element_type_15, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, addmm_4, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, permute_6, add_24, mul_2, convert_element_type_35, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,682] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf88, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf89, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    tmp13 = load(arg14_1, i2)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    return tmp14\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, convert_element_type_4, addmm_11, add_9, arg77_1, mul_25, permute_23, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, sub_2, embedding, permute_13, add_10, convert_element_type_15, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, addmm_4, permute_20, mul_4, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,692] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_4, addmm_11, add_29, convert_element_type_42, add_9, arg77_1, addmm_14, mul_25, permute_23, view_45, _scaled_dot_product_efficient_attention_3, permute_27, convert_element_type_43, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, sub_2, permute_30, embedding, permute_13, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, arg57_1, addmm_4, permute_20, mul_4, arg56_1, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, convert_element_type_24, permute_5, arg32_1, mul_28, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,697] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_4, addmm_11, add_29, convert_element_type_42, add_9, arg77_1, addmm_14, mul_25, permute_23, view_45, _scaled_dot_product_efficient_attention_3, permute_27, convert_element_type_43, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, pow_4, sub_2, permute_30, embedding, permute_13, convert_element_type_44, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, arg57_1, addmm_4, permute_20, mul_4, mul_29, arg56_1, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,701] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, convert_element_type_4, addmm_11, add_29, convert_element_type_42, add_9, arg77_1, addmm_14, mul_25, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, convert_element_type_43, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, pow_4, sub_2, permute_30, embedding, permute_13, convert_element_type_44, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, arg57_1, addmm_4, permute_20, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,707] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf93, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_11, add_29, convert_element_type_42, add_9, arg77_1, addmm_14, mul_25, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, convert_element_type_43, permute_17, rsqrt_2, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, pow_4, sub_2, permute_30, embedding, permute_13, convert_element_type_44, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, view_18, convert_element_type_39, convert_element_type_40, view_43, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, mul_26, iota, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, arg57_1, addmm_4, permute_20, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, mul_31, add, addmm_7, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, split, arg42_1, view, view_39, split_3, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, sub_7, convert_element_type_14, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, mul_28, tanh_1, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, _scaled_dot_product_efficient_attention_1, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,724] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf97, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf99, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf100, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    return tmp15\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_11, add_29, convert_element_type_42, add_9, arg77_1, mul_25, addmm_14, permute_23, view_45, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, pow_4, sub_2, permute_30, embedding, permute_13, convert_element_type_44, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, rsqrt_8, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, addmm_15, add_11, arg40_1, mul_23, addmm_1, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,728] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf97, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf99, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf100, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    tmp16 = load(arg16_1, i2)\n",
      "    tmp17 = tmp15 * tmp16\n",
      "    return tmp17\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_11, convert_element_type_42, add_29, add_9, arg77_1, mul_25, addmm_14, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, view_38, mul_9, mul_8, pow_4, sub_2, permute_30, embedding, mul_33, permute_13, convert_element_type_44, add_10, convert_element_type_15, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, rsqrt_8, arg48_1, view_12, permute_14, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_16, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, view_36, view_17, add_4, arg5_1, view_41, arg41_1, addmm_15, arg40_1, mul_23, addmm_1, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, view_21, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, permute_3, arg28_1, pow_1, rsqrt_5, view_19, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, view_9, arg9_1, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,762] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf97, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf110, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp8 = to_dtype(tmp7, torch.float32)\n",
      "    tmp9 = tmp6 + tmp8\n",
      "    tmp10 = load(buf112, i1 + 256 * i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = load(buf113, i1 + 256 * i0)\n",
      "    tmp13 = index_expr(384, torch.float32)\n",
      "    tmp14 = tmp12 / tmp13\n",
      "    tmp15 = constant(1e-05, torch.float32)\n",
      "    tmp16 = tmp14 + tmp15\n",
      "    tmp17 = rsqrt(tmp16)\n",
      "    tmp18 = tmp11 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_11, mul_34, convert_element_type_42, add_29, add_9, arg77_1, mul_25, addmm_14, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_38, mul_9, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_50, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,766] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf73, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf86, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf97, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf110, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp8 = to_dtype(tmp7, torch.float32)\n",
      "    tmp9 = tmp6 + tmp8\n",
      "    tmp10 = load(buf112, i1 + 256 * i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = load(buf113, i1 + 256 * i0)\n",
      "    tmp13 = index_expr(384, torch.float32)\n",
      "    tmp14 = tmp12 / tmp13\n",
      "    tmp15 = constant(1e-05, torch.float32)\n",
      "    tmp16 = tmp14 + tmp15\n",
      "    tmp17 = rsqrt(tmp16)\n",
      "    tmp18 = tmp11 * tmp17\n",
      "    tmp19 = load(arg18_1, i2)\n",
      "    tmp20 = tmp18 * tmp19\n",
      "    return tmp20\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_11, mul_34, add_29, convert_element_type_42, add_9, arg77_1, mul_25, addmm_14, permute_23, view_45, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_38, mul_9, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, mul_35, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, view_31, arg0_1, view_50, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,778] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, view_57, addmm_11, mul_34, add_29, convert_element_type_42, add_9, arg77_1, mul_25, addmm_14, permute_23, view_45, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, arg65_1, view_38, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, mul_35, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, view_56, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, convert_element_type_53, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_55, convert_element_type_19, mul_19, permute_38, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,782] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, view_57, addmm_11, mul_34, add_29, convert_element_type_42, add_9, arg77_1, mul_25, addmm_14, permute_23, view_45, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, arg65_1, view_38, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, mul_35, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, convert_element_type_56, view_7, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, view_56, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, convert_element_type_53, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_55, convert_element_type_19, mul_19, permute_38, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, mul_37, permute_11, arg11_1, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,787] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, view_57, addmm_11, mul_34, convert_element_type_42, add_29, add_9, arg77_1, mul_25, addmm_14, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, arg65_1, view_38, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, mul_35, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, view_56, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, convert_element_type_53, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_55, convert_element_type_19, mul_19, permute_38, convert_element_type_38, arg26_1, add_14, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_24, mul_18, rsqrt_1, view_34, view_26, addmm_10, split_2, convert_element_type_29, add_38, convert_element_type_32, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, mul_38, view_47, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,793] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf117, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, view_57, addmm_11, mul_34, convert_element_type_42, add_29, add_9, arg77_1, mul_25, addmm_14, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, mul_32, view_51, permute_26, view_40, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, arg65_1, view_38, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, add_12, permute_32, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, mul_35, convert_element_type_30, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, view_56, add_4, arg5_1, view_41, arg41_1, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, convert_element_type_53, var_mean_6, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_55, convert_element_type_19, mul_19, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, view_34, add_39, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, view_37, mul_3, arg12_1, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, sub_4, permute_9, arg10_1, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,809] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf124, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf125, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, addmm_11, view_57, mul_34, add_29, convert_element_type_42, add_9, mul_40, arg77_1, mul_25, addmm_14, permute_23, view_45, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, view_59, mul_32, arg67_1, view_51, permute_26, view_40, var_mean_2, arg66_1, permute_25, permute_28, add_20, convert_element_type_50, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, permute_10, rsqrt_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, view_34, convert_element_type_58, add_39, view_26, addmm_10, split_2, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_35, arg13_1, add_22, addmm_19, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, sub_10, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,812] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf124, i1 + 256 * i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf125, i1 + 256 * i0)\n",
      "    tmp4 = index_expr(384, torch.float32)\n",
      "    tmp5 = tmp3 / tmp4\n",
      "    tmp6 = constant(1e-05, torch.float32)\n",
      "    tmp7 = tmp5 + tmp6\n",
      "    tmp8 = rsqrt(tmp7)\n",
      "    tmp9 = tmp2 * tmp8\n",
      "    tmp10 = load(arg20_1, i2)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    return tmp11\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, addmm_11, view_57, mul_34, convert_element_type_42, add_29, add_9, mul_40, arg77_1, mul_25, addmm_14, view_45, permute_23, add_30, _scaled_dot_product_efficient_attention_3, permute_27, permute_17, convert_element_type_43, rsqrt_2, view_59, mul_32, arg67_1, view_51, permute_26, view_40, arg66_1, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_26, convert_element_type_23, rsqrt_10, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, rsqrt_4, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, arg33_1, tanh_2, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, view_34, convert_element_type_58, add_39, view_26, addmm_10, split_2, arg20_1, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, var_mean_1, arg18_1, view_11, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_35, arg13_1, add_22, addmm_19, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, sub_10, view_23, var_mean_7, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, mul_41, convert_element_type_8, rsqrt_6, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,844] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf135, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf137, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf138, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, convert_element_type_42, add_29, add_9, mul_40, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, view_59, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, mul_42, permute_26, view_40, arg66_1, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, permute_10, rsqrt_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, view_13, view_63, view_35, arg13_1, add_22, addmm_19, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,848] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf135, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf137, i1 + 256 * i0)\n",
      "    tmp5 = tmp3 - tmp4\n",
      "    tmp6 = load(buf138, i1 + 256 * i0)\n",
      "    tmp7 = index_expr(384, torch.float32)\n",
      "    tmp8 = tmp6 / tmp7\n",
      "    tmp9 = constant(1e-05, torch.float32)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = rsqrt(tmp10)\n",
      "    tmp12 = tmp5 * tmp11\n",
      "    tmp13 = load(arg22_1, i2)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    return tmp14\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, add_29, convert_element_type_42, add_9, mul_40, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, mul_43, view_59, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, var_mean_2, arg66_1, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, rsqrt_10, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, mul_24, mul_18, rsqrt_1, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_63, view_35, arg13_1, add_22, addmm_19, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,858] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float16,\n",
      "    tmp0 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, arg72_1, add_29, convert_element_type_42, add_9, mul_40, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, var_mean_2, arg66_1, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_45, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, mul_44, iota, mul_26, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, rsqrt_10, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, view_68, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, rsqrt_1, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, convert_element_type_34, view_13, view_63, addmm_22, view_35, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,863] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = tmp1 * tmp1\n",
      "    tmp3 = tmp2 * tmp1\n",
      "    tmp4 = constant(0.044715, torch.float32)\n",
      "    tmp5 = tmp3 * tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, arg72_1, add_29, convert_element_type_42, add_9, mul_40, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, var_mean_2, arg66_1, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_45, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, convert_element_type_68, _scaled_dot_product_efficient_attention_2, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, rsqrt_10, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, view_68, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, rsqrt_1, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, pow_6, split_2, arg20_1, convert_element_type_29, convert_element_type_32, add_38, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, mul_45, convert_element_type_35, arg14_1, view_13, convert_element_type_34, view_63, addmm_22, view_35, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,868] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = to_dtype(tmp0, torch.float32)\n",
      "    tmp2 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = tmp3 * tmp3\n",
      "    tmp5 = tmp4 * tmp3\n",
      "    tmp6 = constant(0.044715, torch.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = tmp1 + tmp7\n",
      "    tmp9 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, arg72_1, convert_element_type_42, add_29, add_9, mul_40, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, arg66_1, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_45, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, view_42, _scaled_dot_product_efficient_attention_2, convert_element_type_68, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, permute_10, rsqrt_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, view_68, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, add_46, rsqrt_1, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, pow_6, convert_element_type_29, convert_element_type_32, add_38, mul_46, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, mul_45, view_13, view_63, addmm_22, view_35, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,874] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp1 = constant(0.5, torch.float16)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tmp3 = to_dtype(tmp2, torch.float32)\n",
      "    tmp4 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(buf142, i2 + 1536 * i1 + 393216 * i0)\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = tmp7 * tmp7\n",
      "    tmp9 = tmp8 * tmp7\n",
      "    tmp10 = constant(0.044715, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tmp5 + tmp11\n",
      "    tmp13 = constant(0.7978845608028654, torch.float32)\n",
      "    tmp14 = tmp12 * tmp13\n",
      "    tmp15 = tanh(tmp14)\n",
      "    tmp16 = constant(1.0, torch.float32)\n",
      "    tmp17 = tmp15 + tmp16\n",
      "    tmp18 = tmp3 * tmp17\n",
      "    return tmp18\n",
      "    ,\n",
      "    ranges=[128, 256, 1536],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, addmm_11, view_57, mul_34, addmm_20, rsqrt_11, arg72_1, convert_element_type_42, add_29, add_9, mul_40, tanh_5, permute_41, arg77_1, arg71_1, mul_25, addmm_14, view_45, permute_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, arg66_1, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, convert_element_type_44, add_45, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, arg58_1, add_34, view_49, addmm_3, mul_47, view_42, _scaled_dot_product_efficient_attention_2, convert_element_type_68, mul_21, addmm_5, mul_6, convert_element_type_49, mul_44, iota, mul_26, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, add_47, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, sub_3, permute_18, convert_element_type_21, arg44_1, addmm_13, convert_element_type_17, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, permute_10, rsqrt_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, view_68, arg1_1, _scaled_dot_product_efficient_attention_5, permute_31, mul, permute_15, arg2_1, pow_3, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, sub_11, convert_element_type_10, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, rsqrt_1, add_46, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, pow_6, convert_element_type_29, convert_element_type_32, add_38, mul_46, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, mul_45, view_13, view_63, addmm_22, view_35, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,891] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf135, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf146, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf148, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf149, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    return tmp15\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, convert_element_type_4, addmm_18, addmm_11, view_57, arg74_1, mul_34, addmm_20, arg75_1, rsqrt_11, arg72_1, add_29, convert_element_type_42, add_9, mul_40, tanh_5, permute_41, arg77_1, arg71_1, mul_25, addmm_14, permute_23, view_45, addmm_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, rsqrt_12, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, var_mean_2, arg66_1, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, convert_element_type_70, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, permute_47, convert_element_type_44, add_45, convert_element_type_71, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, view_71, arg58_1, add_34, view_49, addmm_3, view_42, mul_47, _scaled_dot_product_efficient_attention_2, convert_element_type_68, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, mul_44, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, arg9_1, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, add_49, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, var_mean_12, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, add_47, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, mul_48, sub_3, permute_18, convert_element_type_21, arg44_1, add_48, addmm_13, convert_element_type_17, sub_12, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, rsqrt_10, permute_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, _scaled_dot_product_efficient_attention_5, view_68, permute_31, mul, permute_15, arg2_1, pow_3, convert_element_type_69, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, view_70, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, convert_element_type_10, sub_11, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, rsqrt_1, add_46, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, pow_6, convert_element_type_29, convert_element_type_32, add_38, mul_46, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, mul_45, view_13, convert_element_type_34, view_63, view_35, addmm_22, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, pow_2, convert_element_type_7, add_11}\n",
      "  )\n",
      "))\n",
      "[2023-07-20 11:51:04,896] torch._inductor.graph: [WARNING] out is : TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf122, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp1 = load(buf135, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp2 = to_dtype(tmp1, torch.float32)\n",
      "    tmp3 = tmp0 + tmp2\n",
      "    tmp4 = load(buf146, i2 + 384 * i1 + 98304 * i0)\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = tmp3 + tmp5\n",
      "    tmp7 = load(buf148, i1 + 256 * i0)\n",
      "    tmp8 = tmp6 - tmp7\n",
      "    tmp9 = load(buf149, i1 + 256 * i0)\n",
      "    tmp10 = index_expr(384, torch.float32)\n",
      "    tmp11 = tmp9 / tmp10\n",
      "    tmp12 = constant(1e-05, torch.float32)\n",
      "    tmp13 = tmp11 + tmp12\n",
      "    tmp14 = rsqrt(tmp13)\n",
      "    tmp15 = tmp8 * tmp14\n",
      "    tmp16 = load(arg24_1, i2)\n",
      "    tmp17 = tmp15 * tmp16\n",
      "    return tmp17\n",
      "    ,\n",
      "    ranges=[128, 256, 384],\n",
      "    origins={arg47_1, tanh_3, addmm_18, convert_element_type_4, addmm_11, view_57, arg74_1, mul_34, addmm_20, arg75_1, rsqrt_11, arg72_1, convert_element_type_42, add_29, add_9, mul_40, tanh_5, permute_41, arg77_1, arg71_1, mul_25, addmm_14, permute_23, view_45, addmm_23, add_30, arg70_1, _scaled_dot_product_efficient_attention_3, permute_40, permute_27, permute_17, convert_element_type_43, var_mean_11, rsqrt_2, arg69_1, rsqrt_12, view_59, mul_43, convert_element_type_62, arg68_1, mul_32, arg67_1, view_51, permute_26, mul_42, view_40, arg66_1, var_mean_2, permute_25, permute_28, add_20, convert_element_type_50, view_62, view_38, arg65_1, mul_9, add_37, arg64_1, mul_8, convert_element_type_70, pow_4, arg63_1, view_54, sub_9, sub_2, permute_30, embedding, arg62_1, mul_33, permute_13, arg61_1, permute_47, convert_element_type_44, add_45, convert_element_type_71, add_10, arg60_1, convert_element_type_15, var_mean_9, convert_element_type_41, convert_element_type_9, arg59_1, view_18, convert_element_type_39, convert_element_type_40, view_43, view_71, arg58_1, add_34, view_49, addmm_3, view_42, mul_47, _scaled_dot_product_efficient_attention_2, convert_element_type_68, mul_21, addmm_5, mul_6, convert_element_type_49, iota, mul_26, mul_44, unsqueeze, convert_element_type_66, add_17, convert_element_type_13, add_15, rsqrt_3, convert_element_type_65, convert_element_type_67, convert_element_type_20, permute_39, add_12, permute_32, addmm_4, permute_20, arg57_1, permute_43, mul_4, arg56_1, mul_29, rsqrt, convert_element_type_16, convert_element_type, split_4, tanh, permute_19, arg55_1, add, addmm_7, mul_31, add_49, sub_8, arg54_1, add_43, add_40, view_20, var_mean_3, arg53_1, permute_12, arg52_1, view_28, sub_1, add_31, add_21, embedding_1, arg51_1, mul_15, addmm_6, view_67, var_mean_10, arg50_1, var_mean_12, addmm_12, add_1, arg49_1, arg48_1, rsqrt_8, add_47, view_12, permute_14, convert_element_type_30, mul_35, permute_29, mul_14, convert_element_type_45, mul_20, permute_22, sub, arg45_1, addmm_17, var_mean, arg46_1, view_66, convert_element_type_3, mul_48, sub_3, permute_18, convert_element_type_21, arg44_1, add_48, addmm_13, convert_element_type_17, sub_12, permute_4, arg43_1, addmm_16, view_6, addmm, add_33, mul_49, split, var_mean_8, arg42_1, view, view_39, split_3, view_46, view_48, mul_27, add_16, convert_element_type_22, convert_element_type_60, convert_element_type_26, convert_element_type_23, permute_10, rsqrt_10, convert_element_type_46, convert_element_type_31, convert_element_type_25, convert_element_type_54, view_31, arg0_1, view_50, tanh_4, view_16, _scaled_dot_product_efficient_attention_4, arg1_1, _scaled_dot_product_efficient_attention_5, view_68, permute_31, mul, permute_15, arg2_1, pow_3, convert_element_type_69, mul_1, permute_16, permute_37, view_33, view_2, arg3_1, view_7, convert_element_type_56, pow_2, arg4_1, add_2, convert_element_type_33, rsqrt_9, view_65, view_36, view_17, add_4, arg5_1, view_41, arg41_1, view_56, permute_35, addmm_15, add_11, arg40_1, mul_23, view_52, addmm_1, permute_34, arg39_1, mul_10, convert_element_type_14, sub_7, add_8, convert_element_type_63, mul_22, arg38_1, permute_24, pow_5, convert_element_type_5, permute_33, convert_element_type_1, arg37_1, split_1, arg36_1, rsqrt_7, convert_element_type_2, add_26, permute, add_19, arg35_1, view_25, view_1, add_42, rsqrt_4, split_5, view_14, var_mean_4, add_3, arg34_1, add_18, add_36, addmm_8, view_24, view_70, convert_element_type_18, addmm_9, convert_element_type_61, arg33_1, tanh_2, view_61, mul_30, convert_element_type_24, permute_5, arg32_1, tanh_1, mul_28, convert_element_type_51, view_21, permute_36, view_4, arg31_1, _scaled_dot_product_efficient_attention, sub_5, permute_8, add_25, mul_16, view_30, view_22, convert_element_type_52, arg30_1, permute_21, view_15, permute_44, view_5, arg29_1, convert_element_type_11, view_29, var_mean_6, convert_element_type_53, mul_12, view_55, permute_3, arg28_1, pow_1, rsqrt_5, view_19, view_53, convert_element_type_48, convert_element_type_27, arg27_1, permute_2, convert_element_type_28, convert_element_type_19, mul_19, convert_element_type_55, permute_38, convert_element_type_38, arg26_1, add_14, mul_39, add_27, mul_17, convert_element_type_59, view_27, view_44, permute_1, view_3, permute_7, arg24_1, convert_element_type_10, sub_11, mul_36, view_69, arg23_1, mul_24, mul_18, permute_46, rsqrt_1, add_46, arg22_1, view_34, convert_element_type_58, addmm_21, add_39, arg21_1, view_26, addmm_10, view_60, convert_element_type_64, split_2, arg20_1, pow_6, convert_element_type_29, convert_element_type_32, add_38, mul_46, add_13, arg19_1, var_mean_5, add_44, var_mean_1, arg18_1, permute_42, view_11, permute_45, addmm_2, view_58, arg17_1, add_6, add_28, view_8, convert_element_type_37, add_23, arg16_1, view_32, convert_element_type_12, arg15_1, permute_6, add_24, mul_2, convert_element_type_35, arg14_1, mul_45, view_13, view_63, view_35, addmm_22, arg13_1, add_22, addmm_19, arg73_1, view_37, mul_3, arg12_1, convert_element_type_57, sub_6, mul_7, permute_11, arg11_1, mul_37, mul_11, add_5, add_41, sub_4, permute_9, arg10_1, view_64, view_23, var_mean_7, sub_10, add_7, arg6_1, view_10, view_47, mul_38, _scaled_dot_product_efficient_attention_1, convert_element_type_47, add_32, convert_element_type_6, arg7_1, convert_element_type_8, rsqrt_6, mul_41, mul_13, convert_element_type_36, arg8_1, mul_5, add_35, view_9, arg9_1, convert_element_type_7, convert_element_type_34}\n",
      "  )\n",
      "))\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.07 GiB (GPU 0; 31.75 GiB total capacity; 29.20 GiB already allocated; 1.22 GiB free; 29.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     param_group[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lr\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m iter_num \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 15\u001b[0m     losses \u001b[39m=\u001b[39m estimate_loss()\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00miter_num\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m losses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m best_val_loss:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     X, Y \u001b[39m=\u001b[39m get_batch(split, gptconf\u001b[39m.\u001b[39mblock_size, batch_size, device)\n\u001b[1;32m     24\u001b[0m     \u001b[39mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 25\u001b[0m         logits, loss \u001b[39m=\u001b[39m model(X, Y)\n\u001b[1;32m     26\u001b[0m     losses[k] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m out[split] \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:82\u001b[0m, in \u001b[0;36mOptimizedModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdynamo_ctx(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orig_mod\u001b[39m.\u001b[39;49mforward)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/workspace/nanoGPT/model.py:178\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, nn\u001b[39m.\u001b[39mEmbedding):\n\u001b[1;32m    176\u001b[0m         torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mnormal_(module\u001b[39m.\u001b[39mweight, mean\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, std\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, idx, targets\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    179\u001b[0m     device \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    180\u001b[0m     b, t \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39msize()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[39m.\u001b[39m\u001b[39m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    210\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2819\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.forward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   2817\u001b[0m full_args\u001b[39m.\u001b[39mextend(params_flat)\n\u001b[1;32m   2818\u001b[0m full_args\u001b[39m.\u001b[39mextend(runtime_args)\n\u001b[0;32m-> 2819\u001b[0m \u001b[39mreturn\u001b[39;00m compiled_fn(full_args)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1222\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1898\u001b[0m, in \u001b[0;36mcreate_runtime_wrapper.<locals>.runtime_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     args_with_synthetic_bases \u001b[39m=\u001b[39m args\n\u001b[1;32m   1897\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39m_force_original_view_tracking(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m-> 1898\u001b[0m     all_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m   1899\u001b[0m         compiled_fn,\n\u001b[1;32m   1900\u001b[0m         args_with_synthetic_bases,\n\u001b[1;32m   1901\u001b[0m         disable_amp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1904\u001b[0m num_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_inputs\n\u001b[1;32m   1905\u001b[0m num_metadata_mutated_inps \u001b[39m=\u001b[39m runtime_metadata\u001b[39m.\u001b[39mnum_mutated_metadata_inputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1247\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m\"\u001b[39m\u001b[39m_boxed_call\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1247\u001b[0m         out \u001b[39m=\u001b[39m normalize_as_list(f(args))\n\u001b[1;32m   1248\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1249\u001b[0m         \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m         \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:248\u001b[0m, in \u001b[0;36malign_inputs.<locals>.run\u001b[0;34m(new_inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m new_inputs[i]\u001b[39m.\u001b[39mdata_ptr() \u001b[39m%\u001b[39m ALIGNMENT:\n\u001b[1;32m    247\u001b[0m         new_inputs[i] \u001b[39m=\u001b[39m clone_preserve_strides(new_inputs[i])\n\u001b[0;32m--> 248\u001b[0m \u001b[39mreturn\u001b[39;00m model(new_inputs)\n",
      "File \u001b[0;32m/tmp/torchinductor_florian/fk/cfk7zrijfomju7p5wd6bw4yrdmsa2d3zvtlfnzj5nhiwh26sosqc.py:1253\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m   1251\u001b[0m triton__14\u001b[39m.\u001b[39mrun(arg76_1, buf151, \u001b[39m19316736\u001b[39m, grid\u001b[39m=\u001b[39mgrid(\u001b[39m19316736\u001b[39m), stream\u001b[39m=\u001b[39mstream0)\n\u001b[1;32m   1252\u001b[0m \u001b[39mdel\u001b[39;00m arg76_1\n\u001b[0;32m-> 1253\u001b[0m buf152 \u001b[39m=\u001b[39m empty_strided((\u001b[39m32768\u001b[39;49m, \u001b[39m50304\u001b[39;49m), (\u001b[39m50304\u001b[39;49m, \u001b[39m1\u001b[39;49m), device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16)\n\u001b[1;32m   1254\u001b[0m extern_kernels\u001b[39m.\u001b[39mmm(as_strided(buf150, (\u001b[39m32768\u001b[39m, \u001b[39m384\u001b[39m), (\u001b[39m384\u001b[39m, \u001b[39m1\u001b[39m)), as_strided(buf151, (\u001b[39m384\u001b[39m, \u001b[39m50304\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m384\u001b[39m)), out\u001b[39m=\u001b[39mbuf152)\n\u001b[1;32m   1255\u001b[0m \u001b[39mdel\u001b[39;00m buf150\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.07 GiB (GPU 0; 31.75 GiB total capacity; 29.20 GiB already allocated; 1.22 GiB free; 29.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "iter_num = 0\n",
    "eval_interval = 100\n",
    "best_val_loss = 0\n",
    "max_iters = 2000\n",
    "log_interval = 10\n",
    "t0 = time.time()\n",
    "while True:\n",
    "    \n",
    "    lr = learning_rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "    if iter_num % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            if iter_num > 0:\n",
    "                checkpoint = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'model_args': gptconf,\n",
    "                    'iter_num': iter_num,\n",
    "                    'best_val_loss': best_val_loss,\n",
    "                }\n",
    "                print(f\"saving checkpoint to {out_dir}\")\n",
    "                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))\n",
    "    for micro_step in range(gradient_accumulation_steps):\n",
    "        with ctx:\n",
    "            logits, loss = model(X, Y)\n",
    "            loss = loss / gradient_accumulation_steps # scale the loss to account for gradient accumulation\n",
    "                # immediately async prefetch next batch while model is doing the forward pass on the GPU\n",
    "        X, Y = get_batch('train', gptconf.block_size, batch_size, device)\n",
    "        # backward pass, with gradient scaling if training in fp16\n",
    "        scaler.scale(loss).backward()\n",
    "    # clip the gradient\n",
    "    if grad_clip != 0.0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "    # step the optimizer and scaler if training in fp16\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # flush the gradients as soon as we can, no need for this memory anymore\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    # timing and logging\n",
    "    t1 = time.time()\n",
    "    dt = t1 - t0\n",
    "    t0 = t1\n",
    "    if iter_num % log_interval == 0:\n",
    "        # get loss as float. note: this is a CPU-GPU sync point\n",
    "        # scale up to undo the division above, approximating the true total loss (exact would have been a sum)\n",
    "        lossf = loss.item() * gradient_accumulation_steps\n",
    "        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms\")\n",
    "\n",
    "    iter_num += 1\n",
    "\n",
    "    if iter_num > max_iters:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "dtype = 'bfloat16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "\n",
    "meta_path = \"./data/shakespeare_char/meta.pkl\"\n",
    "print(f\"Loading meta from {meta_path}...\")\n",
    "with open(meta_path, 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "# TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "stoi, itos = meta['stoi'], meta['itos']\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# encode the beginning of the prompt\n",
    "if start.startswith('FILE:'):\n",
    "    with open(start[5:], 'r', encoding='utf-8') as f:\n",
    "        start = f.read()\n",
    "start_ids = encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for k in range(num_samples):\n",
    "            y = model.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "            print(decode(y[0].tolist()))\n",
    "            print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = {0:0, 1:0, 2:0, 3:0}\n",
    "for i in range (10000):\n",
    "    a[torch.multinomial(torch.tensor([0.25, 0.25, 0.25, 0.25]),1).item()] += 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device_type = 'cuda'\n",
    "batch_size = 64\n",
    "device = torch.device(device_type)\n",
    "\n",
    "train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n",
    "calib_data = train_data[:1000]\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    elif split == 'val':\n",
    "        data = val_data\n",
    "    elif split == 'calib':\n",
    "        data = calib_data\n",
    "    else:\n",
    "        raise ValueError(f\"invalid split: {split}\")\n",
    "    ix = torch.randint(len(data) - 128, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+128]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+128]).astype(np.int64)) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rejectOption import RejectOption\n",
    "from model import BranchyGPT, GPTConfig\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "data_dir = \"data/shakespeare_char\"\n",
    "\n",
    "X,Y = get_batch('calib')\n",
    "\n",
    "# baby GPT model :)\n",
    "n_layer = 6\n",
    "n_head = 6\n",
    "n_embd = 384\n",
    "dropout = 0.2\n",
    "block_size = 256 # context of up to 256 previous characters\n",
    "bias = False # do we use bias inside LayerNorm and Linear layers?\n",
    "\n",
    "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
    "                  bias=bias, vocab_size=65, dropout=dropout)\n",
    "gptconf = GPTConfig(**model_args)\n",
    "model = BranchyGPT(gptconf).to(torch.device('cuda:0'))\n",
    "model = torch.compile(model)\n",
    "print(X.device)\n",
    "print(next(model.parameters()).device)\n",
    "print(model(X)[0].shape)\n",
    "reject_option = RejectOption(dataset=X, model=model)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reject Option sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "\n",
    "from model import GPTConfig, BranchyGPT\n",
    "from rejectOption import get_device, LLMRejectOption\n",
    "\n",
    "out_dir = \"out-shakespeare-char\"\n",
    "model_name = \"mini-gpt\"\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# Load model from checkpoint\n",
    "\n",
    "ckpt_path = os.path.join(out_dir, 'ckpt_' + model_name + '.pt') \n",
    "checkpoint = torch.load(ckpt_path , map_location=device)\n",
    "\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "model = BranchyGPT(gptconf).to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "# load encoder and decoder\n",
    "\n",
    "meta_path = os.path.join('data', checkpoint['config']['dataset'], 'meta.pkl')\n",
    "if os.path.exists(meta_path):\n",
    "    print(f\"Loading meta from {meta_path}...\")\n",
    "    with open(meta_path, 'rb') as f:\n",
    "        meta = pickle.load(f)\n",
    "    # TODO want to make this more general to arbitrary encoder/decoder schemes\n",
    "    stoi, itos = meta['stoi'], meta['itos']\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "    \n",
    "# load reject option\n",
    "reject_option_path = os.path.join(out_dir, 'reject_option_' + model_name + '.pt')\n",
    "reject_repartition = torch.load(reject_option_path)\n",
    "reject_option = LLMRejectOption()\n",
    "reject_option.calibration_set = reject_repartition.T\n",
    "\n",
    "\n",
    "dtype = 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "num_samples = 1\n",
    "max_new_tokens = 50\n",
    "temperature = 1\n",
    "top_k = 40\n",
    "epsilon = 0.9\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if \"cuda\" in str(device):\n",
    "    ctx = torch.cuda.amp.autocast(dtype=ptdtype, device_type=\"cuda\")\n",
    "else:\n",
    "    ctx = nullcontext()\n",
    "\n",
    "\n",
    "\n",
    "# actual inference\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for epsilon in torch.linspace(0.1, 1., 9):\n",
    "            x = (torch.tensor(encode(\"The war\"), dtype=torch.long, device=device)[None, ...])\n",
    "            print(epsilon)\n",
    "            for k in range(num_samples):\n",
    "                y = model.generate(x, max_new_tokens, reject_option, temperature=temperature, top_k=top_k, epsilon=epsilon, decoder=decode)\n",
    "                print(decode(y[0].tolist()))\n",
    "                print('---------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "# read from csv\n",
    "for file in sorted(glob.glob(\"results*.csv\")):\n",
    "    df = pd.read_csv(file)\n",
    "    # print only head, decoded_token\n",
    "    print(file.split(\".csv\")[0].split(\"results\")[1])\n",
    "    #print(df[['head', 'decoded_token']])\n",
    "    print(f\"Budget without reject = {len(df)*6}, with reject : {(df[['head']]+1).sum().to_numpy()}, percentage : {(df[['head']]+1).sum().to_numpy()/(len(df)*6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from contextlib import nullcontext\n",
    "dtype = 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "num_samples = 1\n",
    "max_new_tokens = 50\n",
    "temperature = 1\n",
    "top_k = 40\n",
    "epsilon = 0.9\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if \"cuda\" in str(device):\n",
    "    ctx = torch.cuda.amp.autocast(dtype=ptdtype, device_type=\"cuda\")\n",
    "else:\n",
    "    ctx = nullcontext()\n",
    "\n",
    "\n",
    "\n",
    "# actual inference\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        for epsilon in torch.linspace(0.9, 1., 9):\n",
    "            x = (torch.tensor(encode(\"The war\"), dtype=torch.long, device=device)[None, ...])\n",
    "            print(epsilon)\n",
    "            for k in range(num_samples):\n",
    "                y = model.generate(x, max_new_tokens, reject_option, temperature=temperature, top_k=top_k, epsilon=epsilon, decoder=decode)\n",
    "                print(decode(y[0].tolist()))\n",
    "                print('---------------')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Branchy GPT on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With perplexity\n",
    "\n",
    "dataset = \"shakespeare_char\"\n",
    "data_dir = os.path.join(\"data\", dataset)\n",
    "\n",
    "val_data = np.memmap(os.path.join(data_dir, \"val.bin\"), dtype=np.uint16, mode=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m     hidden_states: Optional[Tuple[torch\u001b[39m.\u001b[39mFloatTensor]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     attentions: Optional[Tuple[torch\u001b[39m.\u001b[39mFloatTensor]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m branchyllama \u001b[39m=\u001b[39m BranchyLlama\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mopenlm-research/open_llama_3b_v2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mBranchyLlama.from_pretrained\u001b[0;34m(pretrained_model_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(pretrained_model_name):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name, output_hidden_states\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mreturn_dict \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mauxiliary_outputs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList(nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mvocab_size, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers))\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, LlamaPreTrainedModel\n",
    "from transformers.utils.generic import ModelOutput\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class BranchyLlama(LlamaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model.return_dict = True\n",
    "        \n",
    "        self.auxiliary_outputs = nn.ModuleList(nn.Linear(self.model.config.hidden_size, self.model.config.vocab_size, bias=False) for _ in range(len(self.model.config.num_hidden_layers)))\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids, labels: Optional[torch.LongTensor] = None, **kwargs):\n",
    "        \n",
    "        output = self.model(input_ids, **kwargs)\n",
    "        \n",
    "        head_outputs = torch.empty((0, input_ids.shape[0], input_ids.shape[1], self.model.config.vocab_size), device=input_ids.device)\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = 0\n",
    "        \n",
    "        for state in output.hidden_states:\n",
    "            head_output = self.auxiliary_outputs[i](state)\n",
    "            head_outputs = torch.cat((head_outputs, head_output.unsqueeze(0)), dim=0)\n",
    "            if labels is not None:\n",
    "                shift_logits = head_output[..., :-1, :].contiguous()\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                # Flatten the tokens\n",
    "                shift_logits = shift_logits.view(-1, self.model.config.vocab_size)\n",
    "                shift_labels = shift_labels.view(-1)\n",
    "                # Enable model parallelism\n",
    "                shift_labels = shift_labels.to(shift_logits.device)\n",
    "                # sum of losses\n",
    "                loss += loss_fct(shift_logits, shift_labels)\n",
    "        head_loss = loss\n",
    "        loss = 0\n",
    "        last_hidden_states = output[0]\n",
    "        logits = self.model.lm_head(last_hidden_states)\n",
    "        if labels is not None:\n",
    "                shift_logits = logits[..., :-1, :].contiguous()\n",
    "                shift_labels = labels[..., 1:].contiguous()\n",
    "                # Flatten the tokens\n",
    "                shift_logits = shift_logits.view(-1, self.model.config.vocab_size)\n",
    "                shift_labels = shift_labels.view(-1)\n",
    "                # Enable model parallelism\n",
    "                shift_labels = shift_labels.to(shift_logits.device)\n",
    "                # sum of losses\n",
    "                loss = loss_fct(shift_logits, shift_labels)        \n",
    "        \n",
    "        # return both the original output and the intermediate outputs\n",
    "        return CausalBranchyLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            head_loss=head_loss,\n",
    "            logits=logits,\n",
    "            head_outputs=head_outputs,\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class CausalBranchyLMOutputWithPast(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    head_loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    head_outputs: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    \n",
    "branchyllama = BranchyLlama(\"openlm-research/open_llama_3b_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BranchyLlama were not initialized from the model checkpoint at openlm-research/open_llama_3b_v2 and are newly initialized: ['auxiliary_outputs.16.weight', 'auxiliary_outputs.19.weight', 'auxiliary_outputs.0.weight', 'auxiliary_outputs.24.weight', 'auxiliary_outputs.14.weight', 'auxiliary_outputs.4.weight', 'auxiliary_outputs.12.weight', 'auxiliary_outputs.18.weight', 'auxiliary_outputs.15.weight', 'auxiliary_outputs.6.weight', 'auxiliary_outputs.10.weight', 'auxiliary_outputs.8.weight', 'auxiliary_outputs.5.weight', 'auxiliary_outputs.22.weight', 'auxiliary_outputs.23.weight', 'auxiliary_outputs.25.weight', 'auxiliary_outputs.2.weight', 'auxiliary_outputs.1.weight', 'auxiliary_outputs.21.weight', 'auxiliary_outputs.11.weight', 'auxiliary_outputs.9.weight', 'auxiliary_outputs.20.weight', 'auxiliary_outputs.17.weight', 'auxiliary_outputs.13.weight', 'auxiliary_outputs.3.weight', 'auxiliary_outputs.7.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BranchyLlamaConfig {\n",
      "  \"_name_or_path\": \"openlm-research/open_llama_3b_v2\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3200,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8640,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 26,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"self_supervision\": true,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.branchymodel import BranchyLlama\n",
    "\n",
    "branchyllamaconf = BranchyLlama.config_class.from_pretrained(\"openlm-research/open_llama_3b_v2\")\n",
    "# TODO Check if this is the right way to do it, because config here is not changing anything while inference\n",
    "branchyllamaconf.self_supervision = True\n",
    "\n",
    "model = BranchyLlama.from_pretrained(\"openlm-research/open_llama_3b_v2\", config=branchyllamaconf)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending batch torch.Size([64, 1])\n",
      "True\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 31.75 GiB total capacity; 28.12 GiB already allocated; 82.94 MiB free; 28.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m batch \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mlogits[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     54\u001b[0m loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m training_args\u001b[39m.\u001b[39mgradient_accumulation_steps\n\u001b[0;32m---> 55\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     56\u001b[0m \u001b[39m#accelerator.backward(loss)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m training_args\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 31.75 GiB total capacity; 28.12 GiB already allocated; 82.94 MiB free; 28.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import random\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=64,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")\n",
    "\n",
    "class RandomIntDataset(Dataset):\n",
    "    def __init__(self, length):\n",
    "        self.len = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randint(0, 32000, (1,))\n",
    "\n",
    "dataloader = DataLoader(RandomIntDataset(training_args.per_device_train_batch_size), batch_size=training_args.per_device_train_batch_size, pin_memory=True)\n",
    "\n",
    "#if training_args.gradient_checkpointing:\n",
    "#    model.gradient_checkpointing_enable()\n",
    "\n",
    "#accelerator = Accelerator()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "#model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)\n",
    "model.to(\"cuda\")\n",
    "model.train()\n",
    "model.lm_head.requires_grad_(False)\n",
    "model.model.requires_grad_(False)\n",
    "model.auxiliary_outputs.requires_grad_(True)\n",
    "batch = next(iter(dataloader)).to(\"cuda\")\n",
    "for step in range(10000):\n",
    "    print(f\"sending batch {batch.shape}\")\n",
    "    output = model(batch)\n",
    "    loss = output.loss\n",
    "    batch = output.logits[-1]\n",
    "    loss = loss / training_args.gradient_accumulation_steps\n",
    "    loss.backward()\n",
    "    #accelerator.backward(loss)\n",
    "    if step % training_args.gradient_accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step} : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7185 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(batch)\n\u001b[1;32m      3\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# only print the first batch for demonstration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/accelerate/data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     current_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(dataloader_iter)\n\u001b[1;32m    385\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/datasets/arrow_dataset.py:2797\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[1;32m   2796\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(keys)\n\u001b[0;32m-> 2797\u001b[0m n_examples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(batch))])\n\u001b[1;32m   2798\u001b[0m \u001b[39mreturn\u001b[39;00m [{col: array[i] \u001b[39mfor\u001b[39;00m col, array \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_examples)]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7185 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break  # only print the first batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sentence: tensor([    1,   364, 29500])\n",
      "True\n",
      "tensor(8.6826, grad_fn=<DivBackward0>)\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "<s>The 2\n",
      "True\n",
      "tensor(9.4311, grad_fn=<DivBackward0>)\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "<s>The 20\n",
      "True\n",
      "tensor(9.3685, grad_fn=<DivBackward0>)\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1])\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "<s>The 201\n",
      "True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst sentence: \u001b[39m\u001b[39m{\u001b[39;00mbase_sentence[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[39m=\u001b[39m model(base_sentence)\n\u001b[1;32m     15\u001b[0m     output \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mloss)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/nanoGPT/src/branchymodel.py:111\u001b[0m, in \u001b[0;36mBranchyLlama.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, self_supervision)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m self_supervision \u001b[39mand\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mself_supervision and labels cannot be specified at the same time\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[0;32m--> 111\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    112\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    113\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    114\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    115\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    116\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    117\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    118\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    119\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    120\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m last_hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    123\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:578\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    570\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    571\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    572\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    576\u001b[0m     )\n\u001b[1;32m    577\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    579\u001b[0m         hidden_states,\n\u001b[1;32m    580\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    581\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    582\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    583\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    584\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    585\u001b[0m     )\n\u001b[1;32m    587\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    589\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:305\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    303\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    304\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 305\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    306\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    308\u001b[0m outputs \u001b[39m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:155\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_proj(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_proj(x)) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mup_proj(x))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 8\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\")\n",
    "\n",
    "base_prompts = [\"The \"] * batch_size\n",
    "base_sentence = torch.tensor([torch.tensor(tokenizer.encode(prompt), dtype=torch.long, device=device).tolist() for prompt in base_prompts])\n",
    "print(f\"first sentence: {base_sentence[0]}\")\n",
    "for i in range(100):\n",
    "    outputs = model(base_sentence)\n",
    "    output = outputs.logits\n",
    "    print(outputs.loss)\n",
    "    print(torch.argmax(torch.softmax(output[-1][:, -1, :], dim=-1).squeeze(), dim=-1).shape)\n",
    "\n",
    "    print(torch.multinomial(torch.softmax(output[-1][:, -1, :], dim=-1).squeeze(), 1).shape)\n",
    "    base_sentence = torch.cat((base_sentence.squeeze(), torch.argmax(torch.softmax(output[-1][:, -1, :], dim=-1).squeeze(), dim=-1).unsqueeze(-1)), dim=-1)\n",
    "    for i in range(batch_size):\n",
    "        print(tokenizer.decode(base_sentence.squeeze()[i].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500],\n",
      "        [    1,   364,   950,  1247,   296,   531,  5629,   325, 29500]])\n",
      "torch.Size([27, 8, 9, 32000])\n",
      "tensor([    1,   364,   950,  1247,   296,   531,  5629,   325, 29500])\n",
      "[29532, 29532, 29532, 29532, 29532, 29532, 29532, 29532]\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([tokenizer.encode(prompt) for prompt in base_prompts], device=device, dtype=torch.long))\n",
    "print(tokenized_base_prompts.logits.shape)\n",
    "\n",
    "logit = tokenized_base_prompts.logits[-1]\n",
    "# for each batch\n",
    "print(torch.tensor([tokenizer.encode(prompt) for prompt in base_prompts], device=device, dtype=torch.long)[0])\n",
    "print(torch.argmax(torch.softmax(logit[:,-1,:], dim=-1), dim=-1).squeeze().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load model directly\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m----> 4\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mopenlm-research/open_llama_7b_v2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mopenlm-research/open_llama_7b_v2\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:691\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    689\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTokenizer class \u001b[39m\u001b[39m{\u001b[39;00mtokenizer_class_candidate\u001b[39m}\u001b[39;00m\u001b[39m does not exist or is not currently imported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m         )\n\u001b[0;32m--> 691\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    693\u001b[0m \u001b[39m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1825\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1823\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1825\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m   1826\u001b[0m     resolved_vocab_files,\n\u001b[1;32m   1827\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   1828\u001b[0m     init_configuration,\n\u001b[1;32m   1829\u001b[0m     \u001b[39m*\u001b[39;49minit_inputs,\n\u001b[1;32m   1830\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1831\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1832\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1833\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1834\u001b[0m     _is_local\u001b[39m=\u001b[39;49mis_local,\n\u001b[1;32m   1835\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1836\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1988\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1986\u001b[0m \u001b[39m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1988\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49minit_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_kwargs)\n\u001b[1;32m   1989\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   1990\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   1991\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1992\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1993\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:93\u001b[0m, in \u001b[0;36mLlamaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, clean_up_tokenization_spaces, unk_token, bos_token, eos_token, add_bos_token, add_eos_token, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m     vocab_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     92\u001b[0m ):\n\u001b[0;32m---> 93\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     94\u001b[0m         vocab_file\u001b[39m=\u001b[39;49mvocab_file,\n\u001b[1;32m     95\u001b[0m         tokenizer_file\u001b[39m=\u001b[39;49mtokenizer_file,\n\u001b[1;32m     96\u001b[0m         clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m     97\u001b[0m         unk_token\u001b[39m=\u001b[39;49munk_token,\n\u001b[1;32m     98\u001b[0m         bos_token\u001b[39m=\u001b[39;49mbos_token,\n\u001b[1;32m     99\u001b[0m         eos_token\u001b[39m=\u001b[39;49meos_token,\n\u001b[1;32m    100\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_bos_token \u001b[39m=\u001b[39m add_bos_token\n\u001b[1;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_eos_token \u001b[39m=\u001b[39m add_eos_token\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:114\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     fast_tokenizer \u001b[39m=\u001b[39m TokenizerFast\u001b[39m.\u001b[39mfrom_file(fast_tokenizer_file)\n\u001b[1;32m    112\u001b[0m \u001b[39melif\u001b[39;00m slow_tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# We need to convert a slow tokenizer to build the backend\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     fast_tokenizer \u001b[39m=\u001b[39m convert_slow_tokenizer(slow_tokenizer)\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslow_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# We need to create and convert a slow tokenizer to build the backend\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     slow_tokenizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslow_tokenizer_class(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1307\u001b[0m, in \u001b[0;36mconvert_slow_tokenizer\u001b[0;34m(transformer_tokenizer)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1300\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn instance of tokenizer class \u001b[39m\u001b[39m{\u001b[39;00mtokenizer_class_name\u001b[39m}\u001b[39;00m\u001b[39m cannot be converted in a Fast tokenizer instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m No converter was found. Currently available slow->fast convertors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1302\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(SLOW_TO_FAST_CONVERTERS\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m     )\n\u001b[1;32m   1305\u001b[0m converter_class \u001b[39m=\u001b[39m SLOW_TO_FAST_CONVERTERS[tokenizer_class_name]\n\u001b[0;32m-> 1307\u001b[0m \u001b[39mreturn\u001b[39;00m converter_class(transformer_tokenizer)\u001b[39m.\u001b[39;49mconverted()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:511\u001b[0m, in \u001b[0;36mSpmConverter.converted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconverted\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tokenizer:\n\u001b[0;32m--> 511\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproto)\n\u001b[1;32m    513\u001b[0m     \u001b[39m# Tokenizer assemble\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     normalizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalizer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:1130\u001b[0m, in \u001b[0;36mLlamaConverter.tokenizer\u001b[0;34m(self, proto)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLlama is supposed to be a BPE model!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1129\u001b[0m \u001b[39melif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1130\u001b[0m     _, merges \u001b[39m=\u001b[39m SentencePieceExtractor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moriginal_tokenizer\u001b[39m.\u001b[39;49mvocab_file)\u001b[39m.\u001b[39;49mextract(vocab_scores)\n\u001b[1;32m   1131\u001b[0m     bpe_vocab \u001b[39m=\u001b[39m {word: i \u001b[39mfor\u001b[39;00m i, (word, _score) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(vocab_scores)}\n\u001b[1;32m   1132\u001b[0m     tokenizer \u001b[39m=\u001b[39m Tokenizer(\n\u001b[1;32m   1133\u001b[0m         BPE(bpe_vocab, merges, unk_token\u001b[39m=\u001b[39mproto\u001b[39m.\u001b[39mtrainer_spec\u001b[39m.\u001b[39munk_piece, fuse_unk\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, byte_fallback\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1134\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:60\u001b[0m, in \u001b[0;36mSentencePieceExtractor.extract\u001b[0;34m(self, vocab_scores)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m piece_r \u001b[39min\u001b[39;00m vocab\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     59\u001b[0m     merge \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpiece_l\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpiece_r\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 60\u001b[0m     piece_score \u001b[39m=\u001b[39m vocab_scores\u001b[39m.\u001b[39;49mget(merge, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m piece_score:\n\u001b[1;32m     62\u001b[0m         merges \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [(piece_l, piece_r, piece_score)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openlm-research/open_llama_7b_v2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openlm-research/open_llama_7b_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "base_sentence = \"The book is on the\"\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "base_sentence = torch.tensor(tokenizer.encode(base_sentence), dtype=torch.long, device=device)[None, ...].to(device)\n",
    "for i in range(100):\n",
    "    output = model(base_sentence)\n",
    "    base_sentence = torch.cat((base_sentence.squeeze(), torch.multinomial(torch.softmax(output[0][:, -1, :], dim=-1).squeeze(), num_samples=1)), dim=-1).unsqueeze(0)\n",
    "    print(tokenizer.decode(base_sentence.squeeze().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"openlm-research/open_llama_3b_v2\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0084, -0.0039, -0.0094,  ..., -0.0258,  0.0275,  0.0083],\n",
      "        [-0.0084,  0.0041, -0.0120,  ..., -0.0012,  0.0023, -0.0426],\n",
      "        [-0.0181, -0.0111, -0.0202,  ...,  0.0223, -0.0132,  0.0280],\n",
      "        ...,\n",
      "        [-0.0600,  0.0631,  0.0010,  ..., -0.0073, -0.0218,  0.0165],\n",
      "        [ 0.0204,  0.0008,  0.0184,  ..., -0.0318,  0.0433, -0.0039],\n",
      "        [ 0.0121,  0.0035, -0.0192,  ...,  0.0313, -0.0073,  0.0310]],\n",
      "       requires_grad=True)\n",
      "dict_keys(['last_hidden_state', 'past_key_values', 'hidden_states', 'attentions'])\n",
      "27\n",
      "torch.Size([1, 3, 3200])\n",
      "27\n",
      "torch.Size([1, 3, 3200])\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(model.auxiliary_outputs[0].weight)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\")\n",
    "\n",
    "output = model.model(torch.tensor(tokenizer.encode(\"The book\"), dtype=torch.long, device=device)[None, ...], output_hidden_states=True)\n",
    "print(output.__dict__.keys())\n",
    "print(len(output[2]))\n",
    "print(output.hidden_states[0].shape)\n",
    "print(len(output.hidden_states))\n",
    "print(output.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithPast' object has no attribute 'head_outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m branchyoutput \u001b[39m=\u001b[39m branchyllama\u001b[39m.\u001b[39mmodel(torch\u001b[39m.\u001b[39mtensor(tokenizer\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mThe book\u001b[39m\u001b[39m\"\u001b[39m), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)[\u001b[39mNone\u001b[39;00m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39m#assert torch.allclose(output.logits, branchyoutput.logits, atol=1e-3)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(branchyoutput\u001b[39m.\u001b[39;49mhead_outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(tokenizer\u001b[39m.\u001b[39mdecode(branchyoutput\u001b[39m.\u001b[39mlogits\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CausalLMOutputWithPast' object has no attribute 'head_outputs'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "device = torch.device(\"cpu\")\n",
    "#output = model(torch.tensor(tokenizer.encode(\"The book\"), dtype=torch.long, device=device)[None, ...])\n",
    "#print(output)\n",
    "branchyoutput = branchyllama.model(torch.tensor(tokenizer.encode(\"The book\"), dtype=torch.long, device=device)[None, ...])\n",
    "#assert torch.allclose(output.logits, branchyoutput.logits, atol=1e-3)\n",
    "print(branchyoutput.head_outputs)\n",
    "print(tokenizer.decode(branchyoutput.logits.argmax(dim=-1).squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(output.hidden_states))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
