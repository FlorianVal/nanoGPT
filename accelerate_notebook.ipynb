{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/florianvalade/.local/lib/python3.8/site-packages (2.14.0)\n",
      "Requirement already satisfied: transformers in /home/florianvalade/.local/lib/python3.8/site-packages (4.30.2)\n",
      "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 8.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.24.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/florianvalade/.local/lib/python3.8/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets) (20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/florianvalade/.local/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/florianvalade/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/florianvalade/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/florianvalade/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/florianvalade/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/florianvalade/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/florianvalade/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.14.0)\n",
      "\u001b[31mERROR: responses 0.18.0 has requirement urllib3>=1.25.10, but you'll have urllib3 1.25.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.0 responses-0.18.0\n",
      "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.8/dist-packages (0.10)\n",
      "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.8/dist-packages (2.0.0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.8/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.0.0) (2.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch==2.0.0) (2.0.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.14.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.16.2)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.34.0)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/lib/python3/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.14.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/lib/python3/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.4.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/lib/python3/dist-packages (from oauth2client->cloud-tpu-client==0.10) (0.2.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0) (62.3.2)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0) (0.34.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0) (3.26.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.0) (15.0.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.58.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.20.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.8)\n",
      "\u001b[31mERROR: torch_xla-2.0-cp310-cp310-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
      "Collecting git+https://github.com/huggingface/accelerate\n",
      "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-a2a0c9__\n",
      "  Running command git clone -q https://github.com/huggingface/accelerate /tmp/pip-req-build-a2a0c9__\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.22.0.dev0) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from accelerate==0.22.0.dev0) (20.3)\n",
      "Requirement already satisfied: psutil in /home/florianvalade/.local/lib/python3.8/site-packages (from accelerate==0.22.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate==0.22.0.dev0) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from accelerate==0.22.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (2.10.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate==0.22.0.dev0) (2.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->accelerate==0.22.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate==0.22.0.dev0) (62.3.2)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate==0.22.0.dev0) (0.34.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate==0.22.0.dev0) (3.26.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate==0.22.0.dev0) (15.0.7)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.22.0.dev0-py3-none-any.whl size=246643 sha256=c3f263806bd022af8e3fcede3e6b1a2787fd883f9ba1a6491609a60b3c472a3f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-otqbllez/wheels/3f/89/7d/47b6949afa88c1fcde5a743260609e1bc080b2d24739caa6cd\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "Successfully installed accelerate-0.22.0.dev0\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers evaluate\n",
    "! pip install cloud-tpu-client==0.10 torch==2.0.0\n",
    "! pip install https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "! pip install git+https://github.com/huggingface/accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianvalade/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mImpossible d’exécuter le code ; la session a été supprimée. Essayez de redémarrer le noyau."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mImpossible d’exécuter le code ; la session a été supprimée. Essayez de redémarrer le noyau."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe Kernel s’est bloqué lors de l’exécution du code dans la cellule active ou une cellule précédente. Veuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. Cliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. Pour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()  # Write a config file\n",
    "os._exit(00)  # Restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': torch.Size([8, 1])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch \n",
    "\n",
    "class RandomIntDataset(Dataset):\n",
    "    def __init__(self, vocab_size):\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"input_ids\": torch.randint(0, self.vocab_size, (1,))}\n",
    "\n",
    "def create_dataloader(vocab_size, batch_size=8):\n",
    "    return DataLoader(RandomIntDataset(vocab_size), batch_size=batch_size)\n",
    "\n",
    "dataloader = create_dataloader(32000)\n",
    "for batch in dataloader:\n",
    "    print({k: v.shape for k, v in batch.items()})\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianvalade/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    set_seed,\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"steps_per_epoch\": 100,\n",
    "    \"validation_steps\": 50,\n",
    "    \"batch_size\": 8, # Actual batch size will this x 8\n",
    "    \"seed\": 42,\n",
    "    \"vocab_size\": 32000,\n",
    "}\n",
    "\n",
    "def training_loop(model):\n",
    "    \n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    # To have only one message (and not 8) per logs of Transformers or Datasets, we set the logging verbosity\n",
    "    # to INFO for the main process only.\n",
    "    if accelerator.is_main_process:\n",
    "        datasets.utils.logging.set_verbosity_warning()\n",
    "        transformers.utils.logging.set_verbosity_info()\n",
    "    else:\n",
    "        datasets.utils.logging.set_verbosity_error()\n",
    "        transformers.utils.logging.set_verbosity_error()\n",
    "        \n",
    "    dataloader = create_dataloader(hyperparameters[\"vocab_size\"], hyperparameters[\"batch_size\"])\n",
    "    \n",
    "    set_seed(hyperparameters[\"seed\"])\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
    "    \n",
    "    # Prepare everything\n",
    "    # There is no specific order to remember, we just need to unpack the objects in the same order we gave them to the\n",
    "    # prepare method.\n",
    "    model, optimizer, dataloader = accelerator.prepare(\n",
    "        model, optimizer, dataloader\n",
    "    )\n",
    "    \n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "\n",
    "    # Instantiate learning rate scheduler after preparing the training dataloader as the prepare method\n",
    "    # may change its length.\n",
    "    lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=100,\n",
    "        num_training_steps=hyperparameters[\"steps_per_epoch\"] * num_epochs,\n",
    "    )\n",
    "    progress_bar = tqdm(range(num_epochs * hyperparameters[\"steps_per_epoch\"]), disable=not accelerator.is_main_process)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        model.lm_head.requires_grad_(False)\n",
    "        model.model.requires_grad_(False)\n",
    "        model.auxiliary_outputs.requires_grad_(True)\n",
    "        batch = next(iter(dataloader))[\"input_ids\"]\n",
    "        for step in range(hyperparameters[\"steps_per_epoch\"]):\n",
    "            outputs = model(batch)\n",
    "            loss = outputs.loss\n",
    "            lm_head_logits = outputs.logits[-1]\n",
    "            accelerator.backward(loss)\n",
    "            \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_description(f\"Epoch {epoch} loss: {loss.item()}\")\n",
    "            batch = torch.cat((batch, torch.multinomial(torch.softmax(lm_head_logits[:, -1, :], dim=-1), 1)), dim=-1)\n",
    "            \n",
    "        model.eval()\n",
    "        batch = next(iter(dataloader))[\"input_ids\"]\n",
    "        eval_loss = 0\n",
    "        for step in range(hyperparameters[\"validation_steps\"]):\n",
    "            outputs = model(batch)\n",
    "            eval_loss += outputs.loss\n",
    "        loss = eval_loss / hyperparameters[\"validation_steps\"]\n",
    "        \n",
    "        accelerator.print(f\"Epoch {epoch} loss: {loss.item()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openlm-research/open_llama_3b_v2 were not used when initializing BranchyLlama: ['model.layers.5.self_attn.q_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.23.mlp.up_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.11.mlp.up_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.11.mlp.down_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.9.input_layernorm.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.21.mlp.down_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.6.mlp.up_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.22.mlp.up_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.10.input_layernorm.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.17.mlp.up_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.25.mlp.down_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.5.input_layernorm.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.self_attn.o_proj.weight']\n",
      "- This IS expected if you are initializing BranchyLlama from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BranchyLlama from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BranchyLlama were not initialized from the model checkpoint at openlm-research/open_llama_3b_v2 and are newly initialized: ['auxiliary_outputs.0.weight', 'auxiliary_outputs.1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BranchyLlama(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
      "          (k_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
      "          (v_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
      "          (o_proj): Linear(in_features=3200, out_features=3200, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
      "          (down_proj): Linear(in_features=8640, out_features=3200, bias=False)\n",
      "          (up_proj): Linear(in_features=3200, out_features=8640, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (auxiliary_outputs): ModuleList(\n",
      "    (0-1): 2 x Linear(in_features=3200, out_features=32000, bias=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from src.branchymodel import BranchyLlama\n",
    "\n",
    "branchyllamaconf = BranchyLlama.config_class.from_pretrained(\n",
    "    \"openlm-research/open_llama_3b_v2\"\n",
    ")\n",
    "branchyllamaconf.self_supervision = True\n",
    "branchyllamaconf.num_hidden_layers = 2\n",
    "model = BranchyLlama.from_pretrained(\n",
    "    \"openlm-research/open_llama_3b_v2\", config=branchyllamaconf\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:XRT configuration not detected. Defaulting to preview PJRT runtime. To silence this warning and continue using PJRT, explicitly set PJRT_DEVICE to a supported device or configure XRT. To disable default device selection, set PJRT_SELECT_DEFAULT_DEVICE=0\n",
      "WARNING:root:For more information about the status of PJRT, see https://github.com/pytorch/xla/blob/master/docs/pjrt.md\n",
      "WARNING:root:libtpu.so and TPU device found. Setting PJRT_DEVICE=TPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.7097679376602173:   1%|          | 2/300 [00:01<02:47,  1.78it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m \u001b[39mimport\u001b[39;00m notebook_launcher\n\u001b[0;32m----> 3\u001b[0m notebook_launcher(training_loop, (model,), num_processes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, mixed_precision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbf16\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/launchers.py:156\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLaunching training on CPU.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m function(\u001b[39m*\u001b[39;49margs)\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     75\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     76\u001b[0m     progress_bar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m     progress_bar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m     batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((batch, torch\u001b[39m.\u001b[39mmultinomial(torch\u001b[39m.\u001b[39msoftmax(lm_head_logits[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m1\u001b[39m)), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(training_loop, (model,), num_processes=1, mixed_precision=\"bf16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
